Parametry: 
- mohlo by se hodit krom vstupů mít u neuronů bias, který se přičte vždy: f(Wh + b)
- parametry modelu jsou Wi, bi, ...

- dělám derivaci podle každého parametru

Hyperparametry: 
- nedokáží se trénovat z trénovací množiny
- např. počet skrýtých vrstev, ...
- hledání skrz grid searche -> prohledávání celého prostoru

- blbě se přes ně derivuje (diskrétní čísla) -> nedají se moc hledat gradient descentem 

Praktické problémy:
- chceme tam data cpát po batchích -> režije začátku vyhodnocování (přesunu na GPU, ...) je velká
- po vrstvách se na síť můžeme dívat jako na maticové / vektorové operace 
    - váhy se aplikují maticovým násobením
    - bias je přičtení vektoru
    - aktivační funkce je per element aplikace aplikační funkce na vektor

    - derivace hledá matice parciálních derivací 
        - hledání derivace to udělá naplácnutí grafu obráceně s derivovanými operacemi ve vrcholech
        - stačí to pak projít -> vypadne nám z toho derivace normálním průchodem grafu
    -> ve skutečnosti je síť "AST" vektorových operací (viz slajd 7)

Derivace soft-maxu
- derivace softmaxu po správné třídě posílá derivaci, která odpovídá zbytku k 1 (to tam chce)
- po špatných posílá to co tam je kladné 
-> -1[isGold] + o(třída) 
  - -G + o
  - -CoMáBýt + CoJe 

- jakmile začne model dělat co má, tak v něm přestanou téct velké derivaci 
- bias softmax nikterak nezmění

Regularizace: 
- pokud overfittuju (jsem dobrý na trénovacích, ale ne testovacích datech) vyplatí se regularizovat

- můžu se zastavit v momentě, kdy se na testovací množině přestanu zlepšovat (i když se stále zlepšuju na trénovací)
- L2 regularizace: Modely menšími parametry bývají generičtější 
    - minimalizujeme Loss(O, X) + lambda*||O||
    - problém nastavit lambdu: sílu regularizace 

    - v SGD se po derivaci z regularizace stane -2*alfa*lambda*Oi
    -> v každém kroku každý parametr snížím o nějakou jeho část

    - parametr nezůstane nenulově relevantní aniž by byl relevantní
    -> pokud bude užitečný jen jednou, tak ho regularizace časem zabije

    - bayesovský pohled: pokud předpokládáme, že malé parametry jsou pravděpodobné, tak vychází z MLE
        - pokud předpokládáme normální rozdělení parametrů a střední hodnotu v 0
        - MAP: single estimate, využívá apriorního rozdělení parametrů
        - Pokud na základě něho uděláme odhad, tak to vede na L2 regularizaci
- L1 regularizace: v neuronových sítích se moc nepoužívá
    - v každém kroce se neodečítá část toho parametru, ale nějaké konstanta


Ensembling:
- kombinace několika (slabších) modelů 
- pokud nejsou dokonale korelované, tak vždy dostaneme nějakou informaci navíc 

- vzhledem k komplexnosti neuronových sítí je malá šance, že vícekrát (i se stejnými daty) natrénuju stejný model
-> natrénuju model vícekrát, pokaždé se naučí něco jiného

- pokud moc drahé, tak můžu vzít snapshoty modelu v průběhu trénování 
-> od nějaké doby jsou rozumně dobré, pořád získám nějakou informaci navíc

- bagging, nasampluju s replacementem víc množin dat
    - v každé budou nějaká data chybět
    - natrénuju víc modelů, každej se spíš naučí nějakou menší feature
    - jejich průměr postihne obecnost

- boosting spojování slabších modelů do silnější
    - postupně se mění váhy modelů & dat která zatím neumíme dobře postihnout


Data augumentation:
- vytvářím větší množství dat z již existujících
- transformace, translace, .. , přidání šumu, ...
    -> zvyšuje šanci na pochopení generických featur
- mixup: konvexní kombinace již existujících dat
    -> zabraňuje "ostrým hranám" v algoritmu -> preferuje soft hrany & lepší generalizaci
    -> alg. se tolik nenaučí přímo rozpoznávat protipříklady z training setu, ale spíš generalizuje
- label smoothing, ...

Early stopping: 
- zastavím model v momentě kdy se začne zvedat test error
- užitečné hlavně u modelů s velkou kapacitou
- prakticky free, stačí dělat semi-pravidelné snapshoty modelu

- po early stopu můžeme teoreticky trénovat i pomocí testovacích dat
    - znovu od začátku po stejný počet updatů / průchodu všemi daty
    - chvíli trénovat dál se všemi daty (dokud loss na původně testovacích nespadne k lossu v době early stopu)
    -> obojí určité nevýhody (viz kniha 246)

- early stopping funguje jako regularizace, protože omezuje prostor parametrů, který se stihne prozkoumat
- např. pro linerání model to odpovídá L2 regularizaci (248)

Dropout: 
- můžeme na něj pohlédnout jako na ensembling metodu, díky které nemusíme trénovat víc modelů
- trénujeme všechny modely "které jde vytvořit smazáním nějaké ne-outputového neuronu"
    -> prkaticky vynásobení outputu neuronu 0

- pro každý minibatch náhodně vytvoříme bitovou masku pro neurony (statická pravděpodobnost dropoutu)
- na batchi pak updatujeme s danou bitovou maskou, u dalšího batche zas nová (jiná) maska, ...

- při trénování minimalizujeme střední hodnotu Lossu sítě přes všechny možné masky (exp mnoho)
- realisticky to odhadujeme samplováním této množiny

- na rozdíl od beggingu dropout vytváří silně korelované modely (sdílené parametry)
-> díky tomu jich ale výsledný model postihne vlastně exponenciálně (257)

- ideální dělat každý minibatch samplingem s replacementem
- alternativně se na to můžeme dívat jako na scaling aktivace faktorem 1/(1-p)

- při inferenci můžeme
    - samplovat z různých masek
    - odhandout pravděpodobnost jedním průchodem plnou sítí s každou váhou z neuronu i znásobenou pravděpodobností, že i nevypadne
        - praktická data ukazují, že je to dobrý způsob
        -> protože je dropout pravděpodobnost konstanta a díky dense propojení odstranení jednoho téměř nikdy nezabije někoho v další vrstvě -> stačí vydělit všechny váhy konstantou a vyhodnotit síť normálně
        - empiricky leckdy funguje líp než Monte Carlo přístup výše
        - pro lineární regresy odpovídá L2 s per input decay rate 

- dropout nemusí jen nulovat, teoreticky by mohl náhodně násobit, dělat jiné modifikace, ...
- netrénuje jenom ensable, ale ensable se sdílenými parametry, tj. ty musí dobře fungovat nezávisle na ostatních parametrech -> robustní celky












