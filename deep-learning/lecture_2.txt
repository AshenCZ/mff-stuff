Machine learning: 
- training set, test set
- optimalizace minimalizuje chybu na training setu
- machine learning se na training setu učí model, který minimalizuje chybu na nových datech (test set)

- chceme nezávislé samplování trénovací a testovací množiny
- chyby
    - underfitting: málo specializované
    - overfitting: příliš specializované na trénovacích datech, včetně naučení šumu

- kapacita modelu: kolik se toho model může naučit
    - souvisí s tím, kolik má parametrů (např. stupeň polynomu)
    - slabý model vede k underfittingu, moc silný model k overfittingu

    - např. když si model zapamatuje všechny trénovací obrázky, tak to není úplně dobře
    - těžké naučit model právě tu věc, co postihuje daný problém a ne nějakou nezávislou externalitu

    - se silnějším modelem stoupá generalizační chyba, pomalu 
    - tréningová chyba naopak klesá pořád

- "No free lunch theorem"
    - v průměru přes všechny distribuce dat budou všechny klasifikační algoritmy stejně "špatné" při klasifikaci nových dat
        - novým datům mohou být přiřazené labely náhodně (to je to co znamneá přes všechny distribuce)
        - dává smysl, pokud nová data budou mít labely úplně náhodně, tak nemají souvislost s trénovací množinou

- Regularizace: 
    - můžeme v rámci ní snižovat kapacitu modelu
    - stejně tak můžeme zaříznout dobu učení modelu : delší doba se chová podobně jako větší kapacita

    - případně se můžeme snažit mít co nejměnší & co nejvíc nulových parametrů : L2 Regularizace
        - přičte se k chybě skrz nějaký parametr, ten říká, jak moc nám na regularizaci záleží

- Hyperparametry: 
    - parametry, které učící algoritmus nenastavuje sám
    - např. počet vrstev, velikost vrstev, aktivační funkce, ...

    - pořídíme si třetí množinu: validační (development) (k trénovací a testovací)
    - natrénuju na trénovací s nějakými hypermarametry, otestuju na validační, změním hypermarametry a natrénuju, otestuju na validační, ...

- Chybová funkce: 
    - Např. MSE: jediné lokální minimum, které je i globální minimum, ...
    - Maximum likelyhood principle: princip designování loss funkcí
        - Hledám parametry takové, aby model s největší pravděpodobností vygeneroval moje data
        - Tj. aby distribuce dat mého modelu byla co nejpodobnější mojí empiricky sledované distribuci

        - Pokud předpokládáme distribuci dat normální, tak MLE vede na MSE (mean squared error)

Optimalizace funkce:
    - Gradient descent: posun ve směru gradientu (vektoru parciálních derivací)

    - Standardní: počítá gradient na všech testovacích datech najednou, trvá dlouho už se nepoužívá
    - Online (stochastic) GD: odhaduje gradient pomocí jednoho náhodného sample, unbiased, noisy 
    - Minibatch SGD: odhaduje gradient pomocí m náhodných samplů
    - supr zdroje k funkcím níže: http://ruder.io/optimizing-gradient-descent/

- Backpropagation: 
    - chain rule, viz slajdy
    - počítám postupně od zadu parciální derivace výsledku podle každého parametru
    - derivace parametru víc k začátku je derivace jeho podle něj * derivace následujících nodů 

- SGD with momentum
    - pamatuju si rychlost sestupu
    - exponenciálně zapomínám dřívější příspěvky k rychlosti (v každém kroku v <- beta*v + alfa*g)
    - upravuju parametry ve směru rychlosti
    - tím, že je to klouzavý průměr gradientů za poslední dobu, tak tím vyřeším např. přeskakování ze strany na stranu v údolí
        - rychlost se postupně nasčítá, aby šla směrem dolů a nepřeskakovala jen ze strany na stranu
        - přírůstky směrem ze strany na stranu se požerou, kladný přírůstek dolu se postupně nasčítá na relevantní hodnotu
    
    - Nesterov momentum
        - Úpravu přes rychlost provedu ještě před počítáním gradientu
        - Viz slajdy

- ADA Grad
    - snaží se adaptivně odhadovat škálování jednotlivých dimenzí 
    - kumuluje si druhé momenty gradientu, jak moc se v téhle dimenzi mění hodnoty
    - gradient se normalizuje odmocninou z druhého momentu

    - pro neuronky moc dobře nefunguje: druhý moment gradiendu postupně roste
        - kroky se postupně zmenšují s odmocninou času
        - RMSProp: druhý moment nenasčítávám, ale počítám exponenciální dočasný průměr (viz dříve)

- ADAM: Adaptive momentum
    - počítá si exponenciální historii prvního i druhého momentu
    - RMSProp + momentum
    - normalizuju a aktualizuju prvním momentem normalizovaný druhým momentem

    - korekce pro prvních x kroků algoritmu, kde nemám žádná historická data (momenty, ...)
        - na začátku to mění velikosti kroků podle toho co se děje¨
        - na začátku se pohybuje opatrně





